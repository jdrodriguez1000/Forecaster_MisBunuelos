{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6921c5d7",
   "metadata": {},
   "source": [
    "\n",
    "# Fase 3: An√°lisis Exploratorio de Datos (EDA)\n",
    "**Proyecto:** Pron√≥stico Mis Bu√±uelos  \n",
    "**Objetivo:** Comprender la din√°mica de la demanda, validar hip√≥tesis de negocio y decisiones de modelado.\n",
    "\n",
    "---\n",
    "\n",
    "## üö´ Reglas de Juego (Anti-Data Leakage)\n",
    "Siguiendo la metodolog√≠a estricta del proyecto, este an√°lisis se rige por el principio **\"Only Eyes on the Past\"**:\n",
    "1.  **Partici√≥n Estricta:** El dataset se dividir√° en Entrenamiento, Validaci√≥n y Pruebas.\n",
    "2.  **Ceguera al Futuro:** Todo an√°lisis de correlaci√≥n, estacionalidad, tendencias y distribuci√≥n se realizar√° **EXCLUSIVAMENTE** sobre el conjunto de **ENTRENAMIENTO**.\n",
    "3.  **Prohibici√≥n de Espionaje:** Los conjuntos de Validaci√≥n y Pruebas solo se visualizar√°n para contexto temporal, pero no influir√°n en la ingenier√≠a de caracter√≠sticas.\n",
    "\n",
    "## üéØ Objetivos Espec√≠ficos\n",
    "1.  Validar la **estacionalidad** (Picos en Dic/Ene y Jun/Jul).\n",
    "2.  Confirmar el impacto de las **promociones** (Abr-May, Sep-Oct).\n",
    "3.  Evaluar la correlaci√≥n de variables **macroecon√≥micas** y de **marketing**.\n",
    "4.  Identificar y caracterizar el periodo de **Pandemia** (\"Cisne Negro\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import warnings\n",
    "\n",
    "# Configuraci√≥n Global\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# L√≥gica robusta para detectar la ra√≠z del proyecto\n",
    "# Si estamos en 'notebooks/', retrocedemos un nivel.\n",
    "_cwd = Path(os.getcwd())\n",
    "BASE_DIR = _cwd.parent if _cwd.name == \"notebooks\" else _cwd\n",
    "\n",
    "# Cargar Configuraci√≥n\n",
    "config_path = BASE_DIR / \"config.yaml\"\n",
    "with open(config_path, \"r\", encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Configuraci√≥n Visual (Rich Aesthetics) & Output Paths\n",
    "viz_config = config['visualization']\n",
    "plt.style.use(viz_config['style'])\n",
    "palette = viz_config['palette']\n",
    "sns.set_palette(palette)\n",
    "\n",
    "# Colores definidos\n",
    "COLOR_TRAIN = viz_config['colors']['train']\n",
    "COLOR_VAL = viz_config['colors']['val']\n",
    "COLOR_TEST = viz_config['colors']['test']\n",
    "COLOR_PANDEMIC = viz_config['colors']['pandemic_highlight']\n",
    "\n",
    "FIG_SIZE_L = tuple(viz_config['figsize_large'])\n",
    "FIG_SIZE_S = tuple(viz_config['figsize_small'])\n",
    "\n",
    "# Rutas de Salida (Lab - Experiments)\n",
    "EXPERIMENT_DIR = BASE_DIR / config['paths']['lab']['base'] / \"phase_03_eda\"\n",
    "FIGURES_DIR = EXPERIMENT_DIR / \"figures\"\n",
    "ARTIFACTS_DIR = EXPERIMENT_DIR / \"artifacts\"\n",
    "\n",
    "# Crear directorios si no existen\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Entorno configurado. Salidas en: {EXPERIMENT_DIR}\")\n",
    "\n",
    "# Estructura para recolectar hallazgos del reporte JSON\n",
    "eda_report = {\n",
    "    \"phase\": \"Phase 3 - Exploratory Data Analysis\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"description\": \"Exploratory analysis of sales, promotions, and macro variables with stationarity tests and outlier detection.\",\n",
    "    \"methodology\": \"Anti-Data Leakage (Only Eyes on Past)\",\n",
    "    \"temporal_partition\": {},\n",
    "    \"data_stats\": {\n",
    "        \"train\": {},\n",
    "        \"val\": {},\n",
    "        \"test\": {}\n",
    "    },\n",
    "    \"business_insights\": {\n",
    "        \"seasonality\": {},\n",
    "        \"promotions\": {},\n",
    "        \"macro_correlations\": {},\n",
    "        \"marketing_lags\": {}\n",
    "    },\n",
    "    \"visualizations\": [],\n",
    "    \"outliers_detected\": {},\n",
    "    \"stationarity_test\": {}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105351af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rutas\n",
    "DATA_PATH = BASE_DIR / config['paths']['data']['cleansed'] / \"master_monthly.parquet\"\n",
    "\n",
    "# Cargar Datos\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "df = df.sort_index()\n",
    "\n",
    "# Validar Integridad B√°sica\n",
    "print(f\"Dataset Maestro Cargado: {df.shape}\")\n",
    "print(f\"Rango de Fechas: {df.index.min().date()} a {df.index.max().date()}\")\n",
    "\n",
    "# Definir Cortes Temporales (Le√≠dos de Config)\n",
    "val_months = config['validation']['val_size_months']\n",
    "test_months = config['validation']['test_size_months']\n",
    "\n",
    "# √çndices de Corte\n",
    "end_train = df.index[- (val_months + test_months) - 1]\n",
    "start_test = df.index[-test_months]\n",
    "start_val = df.index[- (val_months + test_months)]\n",
    "\n",
    "# Partici√≥n\n",
    "df_train = df.loc[:end_train].copy()\n",
    "df_val = df.loc[start_val : start_test - pd.Timedelta(days=1)].copy() # Justo antes de test\n",
    "df_test = df.loc[start_test:].copy()\n",
    "\n",
    "# Guardar Metadata del Split en Reporte\n",
    "eda_report[\"temporal_partition\"] = {\n",
    "    \"train_range\": [str(df_train.index.min().date()), str(df_train.index.max().date())],\n",
    "    \"val_range\": [str(df_val.index.min().date()), str(df_val.index.max().date())],\n",
    "    \"test_range\": [str(df_test.index.min().date()), str(df_test.index.max().date())],\n",
    "    \"train_size\": len(df_train),\n",
    "    \"val_size\": len(df_val),\n",
    "    \"test_size\": len(df_test)\n",
    "}\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"TRAIN: {df_train.index.min().date()} -> {df_train.index.max().date()} (n={len(df_train)})\")\n",
    "print(f\"VAL:   {df_val.index.min().date()} -> {df_val.index.max().date()} (n={len(df_val)})\")\n",
    "print(f\"TEST:  {df_test.index.min().date()} -> {df_test.index.max().date()} (n={len(df_test)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f551a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_detailed_stats(df):\n",
    "    stats = {}\n",
    "    \n",
    "    # Identificar tipos de columnas\n",
    "    all_cols = df.columns.tolist()\n",
    "    \n",
    "    for col in all_cols:\n",
    "        col_data = df[col].dropna()\n",
    "        if col_data.empty: continue\n",
    "        \n",
    "        # 1. Estad√≠sticos principales (num√©ricos)\n",
    "        desc = col_data.describe(percentiles=[.25, .5, .75, .90, .95]).to_dict()\n",
    "        desc['range'] = float(col_data.max() - col_data.min())\n",
    "        desc['median'] = float(col_data.median())\n",
    "        \n",
    "        col_stats = {\n",
    "            \"descriptive\": {k: (float(v) if isinstance(v, (np.number, float, int)) else v) for k, v in desc.items()}\n",
    "        }\n",
    "        \n",
    "        # 2. An√°lisis de Variables Booleanas (0/1 o True/False)\n",
    "        unique_vals = col_data.unique()\n",
    "        is_bool_numeric = set(unique_vals).issubset({0, 1, 0.0, 1.0})\n",
    "        is_bool_type = col_data.dtype == bool or np.issubdtype(col_data.dtype, np.bool_)\n",
    "        \n",
    "        if is_bool_numeric or is_bool_type:\n",
    "            counts = col_data.value_counts(normalize=False).sort_index().to_dict()\n",
    "            proportions = col_data.value_counts(normalize=True).sort_index().to_dict()\n",
    "            col_stats[\"boolean_analysis\"] = {\n",
    "                \"counts\": {str(int(k)): int(v) for k, v in counts.items()},\n",
    "                \"proportions\": {str(int(k)): round(float(v), 4) for k, v in proportions.items()}\n",
    "            }\n",
    "            \n",
    "        # 3. Detecci√≥n de At√≠picos (IQR)\n",
    "        if np.issubdtype(col_data.dtype, np.number) and not set(unique_vals).issubset({0, 1, 0.0, 1.0}):\n",
    "            q1 = col_data.quantile(0.25)\n",
    "            q3 = col_data.quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower_limit = q1 - 1.5 * iqr\n",
    "            upper_limit = q3 + 1.5 * iqr\n",
    "            \n",
    "            outliers = col_data[(col_data < lower_limit) | (col_data > upper_limit)]\n",
    "            \n",
    "            col_stats[\"outliers_iqr\"] = {\n",
    "                \"lower_limit\": round(float(lower_limit), 4),\n",
    "                \"upper_limit\": round(float(upper_limit), 4),\n",
    "                \"count\": int(len(outliers)),\n",
    "                \"percentage\": round(float(len(outliers) / len(col_data)) * 100, 2) if len(col_data) > 0 else 0\n",
    "            }\n",
    "            \n",
    "        stats[col] = col_stats\n",
    "    return stats\n",
    "\n",
    "# Ejecutar para cada set\n",
    "eda_report[\"data_stats\"] = {\n",
    "    \"train\": get_detailed_stats(df_train),\n",
    "    \"val\": get_detailed_stats(df_val),\n",
    "    \"test\": get_detailed_stats(df_test)\n",
    "}\n",
    "\n",
    "# Mostrar resumen de at√≠picos para el reporte r√°pido\n",
    "outlier_summary = {}\n",
    "for col, info in eda_report[\"data_stats\"][\"train\"].items():\n",
    "    if \"outliers_iqr\" in info:\n",
    "        outlier_summary[col] = info[\"outliers_iqr\"][\"count\"]\n",
    "\n",
    "eda_report[\"outliers_detected\"] = outlier_summary\n",
    "\n",
    "# 4. Test de Dickey-Fuller Aumentado (ADF) - Estacionariedad\n",
    "target_col = config['project']['target_column']\n",
    "adf_res = adfuller(df_train[target_col].dropna())\n",
    "\n",
    "eda_report[\"stationarity_test\"] = {\n",
    "    \"variable\": target_col,\n",
    "    \"adf_statistic\": round(float(adf_res[0]), 4),\n",
    "    \"p_value\": round(float(adf_res[1]), 4),\n",
    "    \"is_stationary\": bool(adf_res[1] < 0.05),\n",
    "    \"critical_values\": {k: round(float(v), 4) for k, v in adf_res[4].items()}\n",
    "}\n",
    "\n",
    "print(\"‚úÖ An√°lisis estad√≠stico y detecci√≥n de at√≠picos completado.\")\n",
    "print(f\"At√≠picos detectados en TRAIN: {outlier_summary}\")\n",
    "print(f\"Dickey-Fuller Test (P-Value): {eda_report['stationarity_test']['p_value']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd7531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hip√≥tesis: Cisne Negro (Pandemia)\n",
    "pandemic_cfg = config['business_events']['pandemic']\n",
    "pandemic_start = pd.to_datetime(pandemic_cfg['start_date'])\n",
    "pandemic_end = pd.to_datetime(pandemic_cfg['end_date'])\n",
    "\n",
    "plt.figure(figsize=FIG_SIZE_L)\n",
    "\n",
    "# Plotear Sets\n",
    "plt.plot(df_train.index, df_train['total_unidades_entregadas'], label='Entrenamiento', color=COLOR_TRAIN, linewidth=2)\n",
    "plt.plot(df_val.index, df_val['total_unidades_entregadas'], label='Validaci√≥n', color=COLOR_VAL, linewidth=2)\n",
    "plt.plot(df_test.index, df_test['total_unidades_entregadas'], label='Pruebas (Futuro Simulado)', color=COLOR_TEST, linewidth=2, linestyle='--')\n",
    "\n",
    "# Sombrear Pandemia\n",
    "plt.axvspan(pandemic_start, pandemic_end, color=COLOR_PANDEMIC, alpha=0.2, label=pandemic_cfg['label'])\n",
    "\n",
    "# Decoraci√≥n\n",
    "plt.title(f\"Evoluci√≥n Hist√≥rica de Ventas: {config['project']['name']}\", fontsize=16, fontweight='bold')\n",
    "plt.ylabel(\"Unidades Entregadas\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar Figura\n",
    "fig_name = \"01_serie_temporal_completa.png\"\n",
    "plt.savefig(FIGURES_DIR / fig_name)\n",
    "eda_report[\"visualizations\"].append(fig_name)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Figura guardada: {FIGURES_DIR / fig_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db14756b",
   "metadata": {},
   "source": [
    "\n",
    "## 5. An√°lisis de Estacionalidad (Solo Entrenamiento)\n",
    "Validaci√≥n de la hip√≥tesis del cliente: *\"Picos en Diciembre/Enero y Junio/Julio\".*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8156b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preparar datos: Agregar columnas de mes y a√±o\n",
    "df_train_viz = df_train.copy()\n",
    "df_train_viz['month'] = df_train_viz.index.month\n",
    "df_train_viz['year'] = df_train_viz.index.year\n",
    "\n",
    "plt.figure(figsize=FIG_SIZE_L)\n",
    "sns.boxplot(data=df_train_viz, x='month', y='total_unidades_entregadas', palette=palette)\n",
    "\n",
    "# Highlight meses clave (Hip√≥tesis)\n",
    "meses_pico = [1, 6, 7, 12]\n",
    "for month in meses_pico:\n",
    "    plt.axvline(x=month-1, color='red', alpha=0.1, linestyle='--') # month-1 por √≠ndice 0\n",
    "\n",
    "plt.title(\"Distribuci√≥n de Ventas Mensuales (Boxplot) - Set de Entrenamiento\", fontsize=14)\n",
    "plt.xlabel(\"Mes\")\n",
    "plt.ylabel(\"Ventas\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Guardar Figura\n",
    "fig_name = \"02_estacionalidad_boxplot.png\"\n",
    "plt.savefig(FIGURES_DIR / fig_name)\n",
    "eda_report[\"visualizations\"].append(fig_name)\n",
    "plt.show()\n",
    "\n",
    "# Calcular Estacionalidad Promedio y guardar en reporte\n",
    "seasonal_idx = df_train_viz.groupby('month')['total_unidades_entregadas'].mean()\n",
    "seasonal_idx_norm = seasonal_idx / seasonal_idx.mean()\n",
    "\n",
    "eda_report[\"business_insights\"][\"seasonality\"] = {\n",
    "    \"indices\": seasonal_idx_norm.round(2).to_dict(),\n",
    "    \"peak_months_validated\": [m for m in meses_pico if seasonal_idx_norm[m] > 1.1] # Umbral arbitrario de 1.1 (10% sobre media)\n",
    "}\n",
    "\n",
    "print(\"√çndices Estacionales (Promedio Train):\")\n",
    "print(seasonal_idx_norm.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc8ede",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Validaci√≥n de Promociones\n",
    "Hip√≥tesis: *\"Las promociones en Abr-May y Sep-Oct levantan la venta.\"*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cab4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir Flag de Promo si no existe (usando dias_en_promo > 0)\n",
    "# Nota: 'dias_en_promo' viene de la agregaci√≥n de 'es_promo'\n",
    "df_train_viz['is_promo_month'] = df_train_viz['dias_en_promo'] > 5 # Al menos 5 d√≠as de promo para considerar el mes\n",
    "\n",
    "plt.figure(figsize=FIG_SIZE_S)\n",
    "sns.kdeplot(data=df_train_viz, x='total_unidades_entregadas', hue='is_promo_month', fill=True, common_norm=False, palette='crest')\n",
    "plt.title(\"Distribuci√≥n de Ventas: Meses Promo vs. No Promo (Train)\", fontsize=14)\n",
    "\n",
    "# Guardar Figura\n",
    "fig_name = \"03_impacto_promo_distribucion.png\"\n",
    "plt.savefig(FIGURES_DIR / fig_name)\n",
    "eda_report[\"visualizations\"].append(fig_name)\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠stica descriptiva y Test de Hip√≥tesis (Simplificado)\n",
    "stats_promo = df_train_viz.groupby('is_promo_month')['total_unidades_entregadas'].describe().round(1)\n",
    "eda_report[\"business_insights\"][\"promotions\"] = {\n",
    "    \"stats\": stats_promo.to_dict(),\n",
    "    \"uplift_observed\": bool(stats_promo.loc[True, 'mean'] > stats_promo.loc[False, 'mean']) if True in stats_promo.index else False\n",
    "}\n",
    "print(stats_promo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b681981f",
   "metadata": {},
   "source": [
    "\n",
    "## 7. An√°lisis Multivariado: Macroeconom√≠a\n",
    "Hip√≥tesis: *\"Inflaci√≥n y Desempleo afectan la venta.\"* Analizamos correlaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b1f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seleccionar variables macro y target\n",
    "target = 'total_unidades_entregadas'\n",
    "macro_cols = ['ipc_mensual', 'trm_promedio', 'tasa_desempleo', 'costo_insumos_index', 'confianza_consumidor']\n",
    "cols_to_corr = [target] + [c for c in macro_cols if c in df_train.columns]\n",
    "\n",
    "# Matriz de correlaci√≥n (Solo Train)\n",
    "corr_matrix = df_train[cols_to_corr].corr(method='spearman') # Spearman para capturar no lineales\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", vmin=-1, vmax=1)\n",
    "plt.title(\"Mapa de Calor de Correlaciones (Spearman) - Set de Entrenamiento\", fontsize=14)\n",
    "\n",
    "# Guardar Figura\n",
    "fig_name = \"04_correlacion_heatmap.png\"\n",
    "plt.savefig(FIGURES_DIR / fig_name)\n",
    "eda_report[\"visualizations\"].append(fig_name)\n",
    "plt.show()\n",
    "\n",
    "# Guardar top correlaciones en reporte\n",
    "top_corr = corr_matrix[target].drop(target).sort_values(ascending=False)\n",
    "eda_report[\"business_insights\"][\"macro_correlations\"] = top_corr.round(3).to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbcf1b2",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Impacto de Marketing (Lag Analysis)\n",
    "Hip√≥tesis: *\"La inversi√≥n en RRSS tiene efecto inmediato o rezagado.\"*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a6650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variables de Marketing\n",
    "mkt_cols = ['inversion_total', 'inversion_facebook', 'inversion_instagram']\n",
    "available_mkt = [c for c in mkt_cols if c in df_train.columns]\n",
    "\n",
    "if available_mkt:\n",
    "    for i, col in enumerate(available_mkt):\n",
    "        # Cross Correlation\n",
    "        plt.figure(figsize=FIG_SIZE_S)\n",
    "        plt.xcorr(df_train[col].astype(float), df_train[target].astype(float), maxlags=6, usevlines=True, normed=True)\n",
    "        plt.title(f\"Correlaci√≥n Cruzada: {col} vs Ventas\", fontsize=12)\n",
    "        plt.xlabel(\"Lag (Meses)\")\n",
    "        plt.ylabel(\"Correlaci√≥n\")\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Guardar Figura\n",
    "        fig_name = f\"05_marketing_lag_{col}.png\"\n",
    "        plt.savefig(FIGURES_DIR / fig_name)\n",
    "        eda_report[\"visualizations\"].append(fig_name)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No se encontraron columnas de inversi√≥n de marketing agregadas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca9c0b3",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Din√°mica Temporal (ACF/PACF)\n",
    "Crucial para definir los *Lags* del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4bd332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=FIG_SIZE_L)\n",
    "plt.subplot(121)\n",
    "plot_acf(df_train[target], lags=24, ax=plt.gca())\n",
    "plt.title(\"Autocorrelaci√≥n (ACF)\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_pacf(df_train[target], lags=12, ax=plt.gca())\n",
    "plt.title(\"Autocorrelaci√≥n Parcial (PACF)\")\n",
    "\n",
    "# Guardar Figura\n",
    "fig_name = \"06_autocorrelacion_acf_pacf.png\"\n",
    "plt.savefig(FIGURES_DIR / fig_name)\n",
    "eda_report[\"visualizations\"].append(fig_name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecfaf1c",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Generaci√≥n de Reporte de Fase\n",
    "Compilaci√≥n autom√°tica de hallazgos y metadatos en formato JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "# Generar timestamp para el nombre del archivo\n",
    "timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "report_filename = f\"phase_03_eda_{timestamp_str}.json\"\n",
    "report_path = ARTIFACTS_DIR / report_filename\n",
    "\n",
    "# Guardar JSON\n",
    "with open(report_path, \"w\", encoding='utf-8') as f:\n",
    "    json.dump(eda_report, f, indent=4)\n",
    "    \n",
    "print(f\"‚úÖ Reporte detallado generado en: {report_path}\")\n",
    "print(json.dumps(eda_report, indent=2))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
